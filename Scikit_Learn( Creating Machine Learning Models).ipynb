{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "strategic-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-exemption",
   "metadata": {},
   "source": [
    "# Different stages in Scikit Learn\n",
    "\n",
    "    1) Get Data Ready\n",
    "    2) Pick a model\n",
    "    3) Fit the model to the data and make a prediction\n",
    "    4) Evaluate the model\n",
    "    5) Improve through Experimentation\n",
    "    6) Save and reload the trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "valued-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "What_we_covered=['1) Get Data Ready',\n",
    "    '2) Pick a model',\n",
    "    '3) Fit the model to the data and make a prediction',\n",
    "    '4) Evaluate the model',\n",
    "    '5) Improve through Experimentation',\n",
    "    '6) Save and reload the trained data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "manual-alabama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1) Get Data Ready',\n",
       " '2) Pick a model',\n",
       " '3) Fit the model to the data and make a prediction',\n",
       " '4) Evaluate the model',\n",
       " '5) Improve through Experimentation',\n",
       " '6) Save and reload the trained data']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "What_we_covered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-joseph",
   "metadata": {},
   "source": [
    "# end to end scikit learn workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "planned-variation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart=pd.read_csv('heart-disease.csv')\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-distributor",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "backed-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features matrix\n",
    "x=heart.drop('target',axis=1) # Selecting all the variables as features, except the target which is dependent variable\n",
    "\n",
    "# labels\n",
    "y=heart['target'] # Selecting the target as the label or output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-drove",
   "metadata": {},
   "source": [
    "# Choosing a model and hyperparameters ( we can tune the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "injured-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # Importing Classification model( random forest )\n",
    "clf=RandomForestClassifier() #clf--> classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "brutal-piece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use default parameters for hyperparameter tuning\n",
    "# we can check the parameters using \n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-calculation",
   "metadata": {},
   "source": [
    "# Fitting the model to training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "unlimited-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "southeast-navigator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-adams",
   "metadata": {},
   "source": [
    "# Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ancient-sheriff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "259   38    1   3       120   231    0        1      182      1      3.8   \n",
       "119   46    0   0       138   243    0        0      152      1      0.0   \n",
       "122   41    0   2       112   268    0        0      172      1      0.0   \n",
       "74    43    0   2       122   213    0        1      165      0      0.2   \n",
       "223   56    0   0       200   288    1        0      133      1      4.0   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "99    53    1   2       130   246    1        0      173      0      0.0   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "283   40    1   0       152   223    0        1      181      0      0.0   \n",
       "285   46    1   0       140   311    0        1      120      1      1.8   \n",
       "252   62    0   0       138   294    1        1      106      0      1.9   \n",
       "\n",
       "     slope  ca  thal  \n",
       "259      1   0     3  \n",
       "119      1   0     2  \n",
       "122      2   0     2  \n",
       "74       1   0     2  \n",
       "223      0   2     3  \n",
       "..     ...  ..   ...  \n",
       "99       2   3     2  \n",
       "4        2   0     2  \n",
       "283      2   0     3  \n",
       "285      1   2     3  \n",
       "252      1   3     2  \n",
       "\n",
       "[242 rows x 13 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "related-composition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label=clf.predict(x_test)\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "intelligent-discipline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175    0\n",
       "49     1\n",
       "179    0\n",
       "136    1\n",
       "226    0\n",
       "      ..\n",
       "182    0\n",
       "160    1\n",
       "117    1\n",
       "229    0\n",
       "154    1\n",
       "Name: target, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-therapy",
   "metadata": {},
   "source": [
    "# Evaluate the Model on training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "comparative-password",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_train,y_train) # Score gives us the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "electric-boston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7704918032786885"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-malaysia",
   "metadata": {},
   "source": [
    "# We can also check metrics other than accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "comparable-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "minimal-message",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77        32\n",
      "           1       0.73      0.83      0.77        29\n",
      "\n",
      "    accuracy                           0.77        61\n",
      "   macro avg       0.77      0.77      0.77        61\n",
      "weighted avg       0.78      0.77      0.77        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "concrete-lighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23,  9],\n",
       "       [ 5, 24]], dtype=int64)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "involved-desire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7704918032786885"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-hospital",
   "metadata": {},
   "source": [
    "# Improve the Model (We can change the N-estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "published-dakota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying Model with 10 estimators\n",
      "Model Accuracy on test set:70.49%\n",
      " \n",
      "Trying Model with 20 estimators\n",
      "Model Accuracy on test set:73.77%\n",
      " \n",
      "Trying Model with 30 estimators\n",
      "Model Accuracy on test set:77.05%\n",
      " \n",
      "Trying Model with 40 estimators\n",
      "Model Accuracy on test set:72.13%\n",
      " \n",
      "Trying Model with 50 estimators\n",
      "Model Accuracy on test set:73.77%\n",
      " \n",
      "Trying Model with 60 estimators\n",
      "Model Accuracy on test set:73.77%\n",
      " \n",
      "Trying Model with 70 estimators\n",
      "Model Accuracy on test set:78.69%\n",
      " \n",
      "Trying Model with 80 estimators\n",
      "Model Accuracy on test set:75.41%\n",
      " \n",
      "Trying Model with 90 estimators\n",
      "Model Accuracy on test set:73.77%\n",
      " \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42) # seeding the random values\n",
    "for i in range(10,100,10):\n",
    "    print(f'Trying Model with {i} estimators')\n",
    "    clf=RandomForestClassifier(n_estimators=i).fit(x_train,y_train) # fitting with train data\n",
    "    print(f'Model Accuracy on test set:{clf.score(x_test,y_test)*100:.2f}%') # getting accuracy based on test data\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-monaco",
   "metadata": {},
   "source": [
    "# Save and Reload the trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "continuing-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can do it using Pickle Library\n",
    "import pickle # syntax for the Pickle Library\n",
    "pickle.dump(clf,open('RandomForest_heart_Disease.pkl','wb')) #wb--> write Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "interior-spine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7377049180327869"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can retreive the loaded model\n",
    "loaded_model=pickle.load(open('RandomForest_heart_Disease.pkl','rb')) #rb--> read binary\n",
    "loaded_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-builder",
   "metadata": {},
   "source": [
    "# Category values to Numerical Values\n",
    "   We can change the categorical values to Numerical by two ways:\n",
    "   1) One Hot Encoder\n",
    "     2) Get Dummies Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "alert-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "parental-ivory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors  Price\n",
       "0   Honda  White          35431      4  15323\n",
       "1     BMW   Blue         192714      5  19943\n",
       "2   Honda  White          84714      4  28343\n",
       "3  Toyota  White         154365      4  13434\n",
       "4  Nissan   Blue         181577      3  14043"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales=pd.read_csv('car-sales-extended.csv')\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "sorted-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=car_sales.drop('Price',axis=1)\n",
    "y=car_sales['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "absent-temple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      15323\n",
       "1      19943\n",
       "2      28343\n",
       "3      13434\n",
       "4      14043\n",
       "       ...  \n",
       "995    32042\n",
       "996     5716\n",
       "997    31570\n",
       "998     4001\n",
       "999    12732\n",
       "Name: Price, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "confidential-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "cosmetic-exercise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 90,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-finance",
   "metadata": {},
   "source": [
    "# Now turn the categories into Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-locking",
   "metadata": {},
   "source": [
    "# One Hot Encoder Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "motivated-butterfly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 3.54310e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e+00, 1.92714e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 8.47140e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 6.66040e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.15883e+05],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.48360e+05]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# now we need to define the categorical values\n",
    "cat_values=['Make','Colour','Doors']\n",
    "one_hot=OneHotEncoder()\n",
    "transformer=ColumnTransformer([('one hot',one_hot,cat_values)],remainder='passthrough')\n",
    "transformed_x=transformer.fit_transform(x)\n",
    "transformed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "distributed-electricity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>192714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248360.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    10   11        12\n",
       "0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   35431.0\n",
       "1    1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  192714.0\n",
       "2    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   84714.0\n",
       "3    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  154365.0\n",
       "4    0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  181577.0\n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...\n",
       "995  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   35820.0\n",
       "996  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  155144.0\n",
       "997  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0   66604.0\n",
       "998  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  215883.0\n",
       "999  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  248360.0\n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-ministry",
   "metadata": {},
   "source": [
    "# Get Dummies Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "legislative-christmas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doors</th>\n",
       "      <th>Make_BMW</th>\n",
       "      <th>Make_Honda</th>\n",
       "      <th>Make_Nissan</th>\n",
       "      <th>Make_Toyota</th>\n",
       "      <th>Colour_Black</th>\n",
       "      <th>Colour_Blue</th>\n",
       "      <th>Colour_Green</th>\n",
       "      <th>Colour_Red</th>\n",
       "      <th>Colour_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Doors  Make_BMW  Make_Honda  Make_Nissan  Make_Toyota  Colour_Black  \\\n",
       "0        4         0           1            0            0             0   \n",
       "1        5         1           0            0            0             0   \n",
       "2        4         0           1            0            0             0   \n",
       "3        4         0           0            0            1             0   \n",
       "4        3         0           0            1            0             0   \n",
       "..     ...       ...         ...          ...          ...           ...   \n",
       "995      4         0           0            0            1             1   \n",
       "996      3         0           0            1            0             0   \n",
       "997      4         0           0            1            0             0   \n",
       "998      4         0           1            0            0             0   \n",
       "999      4         0           0            0            1             0   \n",
       "\n",
       "     Colour_Blue  Colour_Green  Colour_Red  Colour_White  \n",
       "0              0             0           0             1  \n",
       "1              1             0           0             0  \n",
       "2              0             0           0             1  \n",
       "3              0             0           0             1  \n",
       "4              1             0           0             0  \n",
       "..           ...           ...         ...           ...  \n",
       "995            0             0           0             0  \n",
       "996            0             0           0             1  \n",
       "997            1             0           0             0  \n",
       "998            0             0           0             1  \n",
       "999            1             0           0             0  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies=pd.get_dummies(car_sales[['Make','Colour','Doors']])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "interpreted-orbit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(transformed_x,y,test_size=0.25)\n",
    "model=RandomForestClassifier(n_estimators=100)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "indie-heater",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "accepted-tennis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-consensus",
   "metadata": {},
   "source": [
    "# Now we can check for the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-center",
   "metadata": {},
   "source": [
    "# There are two ways we can deal with the missing data\n",
    "    1) we can fill them (Imputing)\n",
    "    2) We can remove the samples which contains the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "extraordinary-riverside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_new=pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "car_sales_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "coordinate-grammar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_new.isna().sum() # to list the sum of all the missing values in each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "instructional-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_new['Make'].fillna('missing',inplace=True)# To fill values in place of NAN\n",
    "car_sales_new['Colour'].fillna('missing',inplace=True)\n",
    "car_sales_new['Odometer (KM)'].fillna(car_sales_new['Odometer (KM)'].mean(),inplace=True)\n",
    "car_sales_new['Doors'].fillna(4,inplace=True)\n",
    "\n",
    "# We have to always check while filling the misising values whether we need to add as string or int or float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fiscal-horizontal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              0\n",
       "Colour            0\n",
       "Odometer (KM)     0\n",
       "Doors             0\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "greatest-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting our features and targets\n",
    "x=car_sales_new.drop('Price',axis=1)\n",
    "y=car_sales_new['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "polyphonic-migration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will drop the rest of the NaN values in Price using dropna method\n",
    "car_sales_new.dropna(inplace=True)\n",
    "len(car_sales_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "final-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=car_sales_new.drop('Price',axis=1)\n",
    "y=car_sales_new['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "solved-publicity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        3.54310e+04, 1.53230e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        1.92714e+05, 1.99430e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        8.47140e+04, 2.83430e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 0.00000e+00,\n",
       "        6.66040e+04, 3.15700e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.15883e+05, 4.00100e+03],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.48360e+05, 1.27320e+04]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# now we need to define the categorical values\n",
    "cat_values=['Make','Colour','Doors']\n",
    "one_hot=OneHotEncoder()\n",
    "transformer=ColumnTransformer([('one hot',one_hot,cat_values)],remainder='passthrough')\n",
    "transformed_x=transformer.fit_transform(car_sales_new)\n",
    "transformed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "judicial-applicant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
       "0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "1    1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "3    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "4    0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "945  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "946  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "947  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "948  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "949  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "           14       15  \n",
       "0     35431.0  15323.0  \n",
       "1    192714.0  19943.0  \n",
       "2     84714.0  28343.0  \n",
       "3    154365.0  13434.0  \n",
       "4    181577.0  14043.0  \n",
       "..        ...      ...  \n",
       "945   35820.0  32042.0  \n",
       "946  155144.0   5716.0  \n",
       "947   66604.0  31570.0  \n",
       "948  215883.0   4001.0  \n",
       "949  248360.0  12732.0  \n",
       "\n",
       "[950 rows x 16 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "lucky-productivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(transformed_x,y,test_size=0.25)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "worst-species",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "western-rover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-victorian",
   "metadata": {},
   "source": [
    "# We can also fill missing values using only Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "christian-shade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we will use only sklearn\n",
    "car_sales_renew=pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "car_sales_renew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "nearby-adapter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_renew.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-ground",
   "metadata": {},
   "source": [
    "# Choosing a right model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-membership",
   "metadata": {},
   "source": [
    "# Let us create a model based on sklearn machine learning map...(https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
    "# Lets us import inbuilt Boston Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "express-defensive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'C:\\\\Users\\\\shanm\\\\Desktop\\\\MiniConda\\\\sampleproject\\\\env\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston=load_boston()\n",
    "boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "amended-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we got two arrays data and targets\n",
    "# Let us convert it to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "greater-queens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df=pd.DataFrame(boston['data'],columns=boston['feature_names'])\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "exotic-david",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  targets  \n",
       "0     15.3  396.90   4.98     24.0  \n",
       "1     17.8  396.90   9.14     21.6  \n",
       "2     17.8  392.83   4.03     34.7  \n",
       "3     18.7  394.63   2.94     33.4  \n",
       "4     18.7  396.90   5.33     36.2  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df['targets']=pd.Series(boston['target'])\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "cleared-causing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we follow the chart to build the right model\n",
    "len(boston_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "varied-consent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662221670168522"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we have less than 100k samples so we use ridge regression\n",
    "\n",
    "# Ridge regression model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# create the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data by getting the features from the data frames\n",
    "x=boston_df.drop('targets',axis=1)\n",
    "y=boston_df['targets']\n",
    "\n",
    "# creating the train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "# Instantiate Ridge model\n",
    "model=Ridge()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "honest-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can always improve the model\n",
    "# Here in this case we can check for the Ensemble Regressor for the same Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-neutral",
   "metadata": {},
   "source": [
    "# Checking with the Ensemble Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "seventh-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check with the Random Forest since it is one of the most famous ensemble regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "instructional-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8922527442109116"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# create the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data by getting the features from the data frames\n",
    "x=boston_df.drop('targets',axis=1)\n",
    "y=boston_df['targets']\n",
    "\n",
    "# creating the train test split ( Since we already loaded it earlier we can ignore this)\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "# Instantiate Ridge model\n",
    "model1=RandomForestRegressor()\n",
    "model1.fit(x_train,y_train)\n",
    "\n",
    "model1.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "unnecessary-sharing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662221670168522"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is much better, we can compare the results\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-fantasy",
   "metadata": {},
   "source": [
    "# Choosing and estimating for the Classification\n",
    "   Lets check the map https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "dynamic-current",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let us take the heart disease example, since it is based on classification\n",
    "hd=pd.read_csv('heart-disease.csv')\n",
    "hd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "clean-british",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the no of samples\n",
    "len(hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "funky-latin",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8688524590163934"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#samples less than 100k, so we use Linear SVC classification\n",
    "\n",
    "# Linear SVC model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# create the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data by getting the features from the data frames\n",
    "x=hd.drop('target',axis=1)\n",
    "y=hd['target']\n",
    "\n",
    "# creating the train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "# Instantiate Ridge model\n",
    "model=LinearSVC(max_iter=1000000)\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "auburn-responsibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try the same with the ensemble Classifier\n",
    "\n",
    "# Random Forest Classifier Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data by getting the features from the data frames\n",
    "x=hd.drop('target',axis=1)\n",
    "y=hd['target']\n",
    "\n",
    "# creating the train test split ( Since we already loaded it earlier we can ignore this)\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "# Instantiate Ridge model\n",
    "clf=RandomForestClassifier()\n",
    "\n",
    "# Fitting the model\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "# Evaluating the model\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "greatest-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hence we can compare which one is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-surgeon",
   "metadata": {},
   "source": [
    "# 1) If we have structured data, we have to use ensemble methods\n",
    "# 2) If we have Unstructured data, we have to use deep learning or transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-shock",
   "metadata": {},
   "source": [
    "### making predictions in our model\n",
    "We can make predictions as below:\n",
    "1. 'predict()'\n",
    "2. 'predict_proba()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "sapphire-nudist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us check predict() first\n",
    "clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "damaged-dress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "frequent-florist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing our results to evaluate the model\n",
    "\n",
    "y_predict=clf.predict(x_test)\n",
    "np.mean(y_predict== y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "supposed-typing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "alpha-knock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also check accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_predict,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "systematic-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see all these are same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-medicine",
   "metadata": {},
   "source": [
    "# Now lets us find what is predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "expected-opinion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95, 0.05],\n",
       "       [0.38, 0.62],\n",
       "       [0.45, 0.55],\n",
       "       [0.86, 0.14],\n",
       "       [0.21, 0.79],\n",
       "       [0.16, 0.84],\n",
       "       [0.36, 0.64],\n",
       "       [0.95, 0.05],\n",
       "       [0.96, 0.04],\n",
       "       [0.53, 0.47]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(x_test)[:10]\n",
    "# this is basically the probability, we can see if the left one is greater then it is 0, else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-landscape",
   "metadata": {},
   "source": [
    "# Evaluating a Machine Learning Model\n",
    "\n",
    "There are three ways to evaluate the sklearn model\n",
    "* Estimator `Score` Method\n",
    "* The `Scoring` parameter\n",
    "* Using different `Metrics`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-progressive",
   "metadata": {},
   "source": [
    "### We can check the methods here...https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-framing",
   "metadata": {},
   "source": [
    "# a) Evaluating using score method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "mineral-utility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us get the model first\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(42)\n",
    "hd=pd.read_csv('heart-disease.csv')\n",
    "hd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "special-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geting the data\n",
    "x=hd.drop('target',axis=1)\n",
    "y=hd['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "completed-performance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "#fit the data\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "#Evaluating the model\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "express-boost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "hd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "prerequisite-vitamin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=hd.drop('target',axis=1)\n",
    "y=hd['target']\n",
    "\n",
    "np.random.seed(42)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "korean-heating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.86885246, 0.81967213, 0.78333333, 0.76666667])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp=cross_val_score(clf,x,y,cv=5) \n",
    "pp\n",
    "\n",
    "# cross validation checks for all the probable test sizes based on the number of cross validation count( which is 'cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "wireless-romania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811639344262295"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cross_val_score=np.mean(pp) # this the score when we evaluate using the scoring method\n",
    "\n",
    "clf_cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "elect-evanescence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8524590163934426, 0.811639344262295)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can compare the two results\n",
    "\n",
    "clf.score(x_test,y_test),clf_cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-certificate",
   "metadata": {},
   "source": [
    "### Evaluating the model using the metrics\n",
    "Here there are different sub categories\n",
    "\n",
    "1. Accuracy\n",
    "2. Area under the ROC Curve\n",
    "3. confusion matrix\n",
    "4. classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-repair",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "greater-california",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811639344262295"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "x=hd.drop('target',axis=1)\n",
    "y=hd['target']\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "cvs=cross_val_score(clf,x,y,cv=5)\n",
    "\n",
    "cross_val_score=np.mean(cvs)\n",
    "cross_val_score # This the final accuracy we have obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "digital-grain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of heart disease is:81.16%\n"
     ]
    }
   ],
   "source": [
    "# We can fancy this by writing\n",
    "print(f'The percentage of heart disease is:{cross_val_score*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-contributor",
   "metadata": {},
   "source": [
    "### We always need to check other results before finalising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-disclosure",
   "metadata": {},
   "source": [
    "# Area under the ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-mileage",
   "metadata": {},
   "source": [
    "### ROC- Receiver operating characteristic curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-singapore",
   "metadata": {},
   "source": [
    "* ROC curves are a comparision of model's true positive rate (tpr) and false positive rate (fpr)\n",
    "* True Positive = model predicts `1` when truth is `1`\n",
    "* False Positive= model predicts `1` when truth is `0`\n",
    "* True Negative= model predicts `0` when truth is `0`\n",
    "* False Negative= model predicts `0` when truth is `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "subtle-repeat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting pur model ready\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x=hd.drop('target',axis=1)\n",
    "y=hd['target']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "strange-education",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89, 0.11],\n",
       "       [0.49, 0.51],\n",
       "       [0.43, 0.57],\n",
       "       [0.84, 0.16],\n",
       "       [0.18, 0.82],\n",
       "       [0.14, 0.86],\n",
       "       [0.36, 0.64],\n",
       "       [0.95, 0.05],\n",
       "       [0.99, 0.01],\n",
       "       [0.47, 0.53]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba=clf.predict_proba(x_test)\n",
    "y_proba[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "crucial-banks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11, 0.51, 0.57, 0.16, 0.82])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need only 1's, hence we can use slicing here\n",
    "y_proba_positive=y_proba[:,1]\n",
    "y_proba_positive[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "confirmed-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the roc curve\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_proba_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "willing-cradle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.06896552,\n",
       "       0.06896552, 0.10344828, 0.13793103, 0.13793103, 0.17241379,\n",
       "       0.17241379, 0.27586207, 0.4137931 , 0.48275862, 0.55172414,\n",
       "       0.65517241, 0.72413793, 0.72413793, 0.82758621, 1.        ])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False positive rate\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "recreational-hurricane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.     , 0.03125, 0.09375, 0.375  , 0.4375 , 0.4375 , 0.46875,\n",
       "       0.59375, 0.6875 , 0.6875 , 0.71875, 0.75   , 0.75   , 0.875  ,\n",
       "       0.875  , 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875,\n",
       "       0.96875, 1.     , 1.     , 1.     ])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true positive rate\n",
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "confident-memphis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC_Curve')"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we already know that this metric is comparision if tpr vs fpr\n",
    "\n",
    "# Importing relevant library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting graph for comaparision\n",
    "plt.plot(fpr,tpr,c='orange')\n",
    "\n",
    "# connecting the corners to find the area between the curve easily\n",
    "plt.plot([0,1],[0,1],c='blue',linestyle='solid')\n",
    "\n",
    "# Customizing the graph\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC_Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "fresh-welding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304956896551724"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now finally to get the area under the curve\n",
    "np.random.seed(25)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,y_proba_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-cattle",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "superb-nowhere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\shanm\\desktop\\miniconda\\sampleproject\\env\\lib\\site-packages (0.11.1)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\shanm\\desktop\\miniconda\\sampleproject\\env\\lib\\site-packages (from seaborn) (1.2.1)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\shanm\\desktop\\miniconda\\sampleproject\\env\\lib\\site-packages (from seaborn) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\shanm\\desktop\\miniconda\\sampleproject\\env\\lib\\site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\shanm\\desktop\\miniconda\\sampleproject\\env\\lib\\site-packages (from seaborn) (3.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\shanm\\desktop\\miniconda\\sampleproject\\env\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shanm\\desktop\\miniconda\\sampleproject\\env\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\shanm\\desktop\\miniconda\\sampleproject\\env\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.1.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\shanm\\desktop\\miniconda\\sampleproject\\env\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2020.12.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\shanm\\desktop\\miniconda\\sampleproject\\env\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\shanm\\desktop\\miniconda\\sampleproject\\env\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\shanm\\desktop\\miniconda\\sampleproject\\env\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\shanm\\desktop\\miniconda\\sampleproject\\env\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "verified-signature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_predict=clf.predict(x_test)\n",
    "conf_mat=confusion_matrix(y_predict,y_test)\n",
    "sns.heatmap(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "premium-valuation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>39343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "      <td>46205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>37731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>43525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "      <td>39891.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YearsExperience   Salary\n",
       "0              1.1  39343.0\n",
       "1              1.3  46205.0\n",
       "2              1.5  37731.0\n",
       "3              2.0  43525.0\n",
       "4              2.2  39891.0"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne=pd.read_csv('P12-SalaryData.csv')\n",
    "ne.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-outline",
   "metadata": {},
   "source": [
    "**Confusion Matrix**\n",
    "\n",
    "A confusion matrix is a quick way to compare the labels the model prdicts and the actual it is suppose to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "introductory-narrative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  5],\n",
       "       [ 4, 28]], dtype=int64)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_preds=clf.predict(x_test)\n",
    "cm=confusion_matrix(y_test,y_preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "statewide-boulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(30.5, 0.5, 'Predicted values')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Heat map\n",
    "sns.heatmap(cm)\n",
    "\n",
    "# Visualization\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-breath",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "contrary-mortality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84        29\n",
      "           1       0.85      0.88      0.86        32\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-engagement",
   "metadata": {},
   "source": [
    "**Precision**: No False Positives\n",
    "\n",
    "**Recall**   : No False Negatives\n",
    "\n",
    "**F1 Score** : Combination of precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-million",
   "metadata": {},
   "source": [
    "# Evaluating a Regression model\n",
    "\n",
    "Most common regression evaluaation techniques are:\n",
    "  \n",
    "1) R^2 or Coefficient of determination\n",
    "\n",
    "2) Mean absolute error (MAE)\n",
    "\n",
    "3) Mean Squared error(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "municipal-decrease",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8213484449305969"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data and fit a regression Model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(25)\n",
    "\n",
    "x=boston_df.drop('targets',axis=1)\n",
    "y=boston_df['targets']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "y_preds=model.predict(x_test)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "color-plain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8213484449305969"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R^2 \n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_preds)\n",
    "\n",
    "# We can see both the r2 and score are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "homeless-general",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3689019607843136"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae=mean_absolute_error(y_test,y_preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "structural-shelf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.184987352941178"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse=mean_squared_error(y_test,y_preds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-billy",
   "metadata": {},
   "source": [
    "# b) Evaluating with a cross validation  and scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "aerial-biography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.86885246, 0.83606557, 0.81666667, 0.76666667])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(25)\n",
    "\n",
    "#data\n",
    "x=hd.drop('target',axis=1)\n",
    "y=hd['target']\n",
    "\n",
    "#Using cross validation score\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "c_val=cross_val_score(clf,x,y,cv=5,scoring=None)\n",
    "c_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "miniature-communication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8215846994535518"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "np.mean(c_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "finished-wyoming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:82.16%\n"
     ]
    }
   ],
   "source": [
    "# Using format method (just for understanding )\n",
    "print(f'The accuracy is:{np.mean(c_val)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-proportion",
   "metadata": {},
   "source": [
    "# Now we will use `accuracy` as scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "molecular-priority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:82.16%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(25)\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "c_val=cross_val_score(clf,x,y,cv=5,scoring='accuracy')\n",
    "print(f'The accuracy is:{np.mean(c_val)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-mixture",
   "metadata": {},
   "source": [
    "# Now we will use `precision` as scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "working-gauge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:83.48%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(25)\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "c_val=cross_val_score(clf,x,y,cv=5,scoring='precision')\n",
    "print(f'The accuracy is:{np.mean(c_val)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-donor",
   "metadata": {},
   "source": [
    "# Now we will use `Recall` as scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "rapid-moore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:84.24%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(25)\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "c_val=cross_val_score(clf,x,y,cv=5,scoring='recall')\n",
    "print(f'The accuracy is:{np.mean(c_val)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-charlotte",
   "metadata": {},
   "source": [
    "# Now we will use `f1-score` as scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "starting-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:83.78%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(25)\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "c_val=cross_val_score(clf,x,y,cv=5,scoring='f1')\n",
    "print(f'The accuracy is:{np.mean(c_val)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-cross",
   "metadata": {},
   "source": [
    "# Up until now we have done for Random Forest Classifier, let us do it for Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "architectural-french",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  targets  \n",
       "0     15.3  396.90   4.98     24.0  \n",
       "1     17.8  396.90   9.14     21.6  \n",
       "2     17.8  392.83   4.03     34.7  \n",
       "3     18.7  394.63   2.94     33.4  \n",
       "4     18.7  396.90   5.33     36.2  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "stainless-copyright",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7645655 , 0.85647474, 0.73224204, 0.49086358, 0.246592  ])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(25)\n",
    "\n",
    "x=boston_df.drop('targets',axis=1)\n",
    "y=boston_df['targets']\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "c_val1=cross_val_score(model,x,y,cv=5,scoring=None)\n",
    "c_val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "biblical-poker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:61.81%\n"
     ]
    }
   ],
   "source": [
    "np.mean(c_val1)\n",
    "print(f'The accuracy is:{np.mean(c_val1)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-brisbane",
   "metadata": {},
   "source": [
    "# Now we will use `Mean Absolute Error` as scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "streaming-moses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean error is:-2.999139526305571\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(25)\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "c_val_mae=cross_val_score(model,x,y,cv=5,scoring='neg_mean_absolute_error')\n",
    "print(f'The Mean error is:{np.mean(c_val_mae)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-simple",
   "metadata": {},
   "source": [
    "# Now we will use `Mean Squared Error` as scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "centered-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean error is:-21.465997021257998\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(25)\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "c_val_mse=cross_val_score(model,x,y,cv=5,scoring='neg_mean_squared_error')\n",
    "print(f'The Mean error is:{np.mean(c_val_mse)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-veteran",
   "metadata": {},
   "source": [
    "# Now we will use `r^2(R-sqaured)` as scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "light-evanescence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean error is:0.6181475720949885\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(25)\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "c_val_r2=cross_val_score(model,x,y,cv=5,scoring='r2')\n",
    "print(f'The Mean error is:{np.mean(c_val_r2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-latter",
   "metadata": {},
   "source": [
    "# c) Evaluating using Metric functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-improvement",
   "metadata": {},
   "source": [
    "**Classification Metric Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "posted-andrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics of Heart Disease DataSet\n",
      "\n",
      "\n",
      "Accuracy Score    :78.68852459016394%\n",
      "Precision Score   :77.14285714285715%\n",
      "Recall Score      :84.375%\n",
      "F1 Score          :80.59701492537314%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,accuracy_score,recall_score,f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(25)\n",
    "\n",
    "x=hd.drop('target',axis=1)\n",
    "y=hd['target']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "y_preds=clf.predict(x_test)\n",
    "\n",
    "print('Classification metrics of Heart Disease DataSet\\n\\n')\n",
    "print(f'Accuracy Score    :{accuracy_score(y_test,y_preds)*100}%')\n",
    "print(f'Precision Score   :{precision_score(y_test,y_preds)*100}%')\n",
    "print(f'Recall Score      :{recall_score(y_test,y_preds)*100}%')\n",
    "print(f'F1 Score          :{f1_score(y_test,y_preds)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-college",
   "metadata": {},
   "source": [
    "**Regression Metric Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "rural-missouri",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression metrics of Heart Disease DataSet\n",
      "\n",
      "\n",
      "mean_squared_error         :12.184987352941178\n",
      "mean_absolute_error        :2.3689019607843136\n",
      "explained_variance_score   :82.14100916195726%\n",
      "r2_score                   :82.13484449305969%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(25)\n",
    "\n",
    "x=boston_df.drop('targets',axis=1)\n",
    "y=boston_df['targets']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "y_preds=model.predict(x_test)\n",
    "\n",
    "print('Regression metrics of Heart Disease DataSet\\n\\n')\n",
    "print(f'mean_squared_error         :{mean_squared_error(y_test,y_preds)}')\n",
    "print(f'mean_absolute_error        :{mean_absolute_error(y_test,y_preds)}')\n",
    "print(f'explained_variance_score   :{explained_variance_score(y_test,y_preds)*100}%')\n",
    "print(f'r2_score                   :{r2_score(y_test,y_preds)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-destination",
   "metadata": {},
   "source": [
    "# Now we need to improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-person",
   "metadata": {},
   "source": [
    "# This can be done by using Hyper parameter Fine Tuning\n",
    "\n",
    "This is basically the inclusion of the validation set\n",
    "\n",
    "Now we have training set, vaidation set and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-algebra",
   "metadata": {},
   "source": [
    "Now this can be done in three ways:\n",
    "1) By Hand\n",
    "\n",
    "2) By RandomSearchCV\n",
    "\n",
    "3) By GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-example",
   "metadata": {},
   "source": [
    "# Hyper parameters by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "selective-cookie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params() \n",
    "# These are the hyperparameters for the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-night",
   "metadata": {},
   "source": [
    "# Now we can filter the best hyper paramters so that we can check for everything\n",
    "Lets us check the top hyperparamters\n",
    "\n",
    "* `max_depth`\n",
    "* `max_features`\n",
    "* `min_samples_leaf`\n",
    "* `min_samples_split`\n",
    "* `n_estimators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "pleasant-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evae_score(y_test,y_preds):\n",
    "    accuracy=accuracy_score(y_test,y_preds)\n",
    "    precision=precision_score(y_test,y_preds)\n",
    "    recall=recall_score(y_test,y_preds)\n",
    "    f1=f1_score(y_test,y_preds)\n",
    "    print(f'Accuracy Score    :{accuracy*100}%')\n",
    "    print(f'Precision Score   :{precision*100}%')\n",
    "    print(f'Recall Score      :{recall*100}%')\n",
    "    print(f'F1 Score          :{f1*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "exclusive-minimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 45, 46)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For more effective solution, try to randomize the entire set\n",
    "hd_shuffled=hd.sample(frac=1)\n",
    "\n",
    "x=hd_shuffled.drop('target',axis=1)\n",
    "y=hd_shuffled['target']\n",
    "\n",
    "#split the data into validation, train and test splits using the shuffled dataset\n",
    "\n",
    "train_split=round(0.7* len(hd_shuffled)) # 70% of data\n",
    "valid_split=round(train_split+0.15*len(hd_shuffled)) #15% of data\n",
    "\n",
    "x_train,y_train=x[:train_split],y[:train_split]\n",
    "\n",
    "x_valid,y_valid=x[train_split:valid_split],y[train_split:valid_split]\n",
    "\n",
    "x_test,y_test=x[valid_split:],y[valid_split:]\n",
    "\n",
    "len(x_train),len(x_valid),len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "irish-olympus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score    :84.44444444444444%\n",
      "Precision Score   :90.47619047619048%\n",
      "Recall Score      :79.16666666666666%\n",
      "F1 Score          :84.44444444444444%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(25)\n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_preds=clf.predict(x_valid)\n",
    "\n",
    "baseline_metrics=evae_score(y_valid,y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-harvey",
   "metadata": {},
   "source": [
    "# Now we perform for the same model with different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "coordinate-mexico",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score    :84.44444444444444%\n",
      "Precision Score   :90.47619047619048%\n",
      "Recall Score      :79.16666666666666%\n",
      "F1 Score          :84.44444444444444%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(25)\n",
    "clf1=RandomForestClassifier(n_estimators=100,min_samples_split=2)\n",
    "clf1.fit(x_train,y_train)\n",
    "y_preds1=clf1.predict(x_valid)\n",
    "\n",
    "clf1_score=evae_score(y_valid,y_preds1)\n",
    "clf1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-insider",
   "metadata": {},
   "source": [
    "# Hyperparameters by Randomsearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "statutory-chess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30, total=   0.9s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30, total=   0.8s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30, total=   0.8s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30, total=   0.8s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.2s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.1s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.1s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.1s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.0s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.8s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.8s\n",
      "[CV] n_estimators=300, min_samples_split=4, min_samples_leaf=3, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=300, min_samples_split=4, min_samples_leaf=3, max_features=sqrt, max_depth=10, total=   1.3s\n",
      "[CV] n_estimators=300, min_samples_split=4, min_samples_leaf=3, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=300, min_samples_split=4, min_samples_leaf=3, max_features=sqrt, max_depth=10, total=   1.1s\n",
      "[CV] n_estimators=300, min_samples_split=4, min_samples_leaf=3, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=300, min_samples_split=4, min_samples_leaf=3, max_features=sqrt, max_depth=10, total=   1.0s\n",
      "[CV] n_estimators=300, min_samples_split=4, min_samples_leaf=3, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=300, min_samples_split=4, min_samples_leaf=3, max_features=sqrt, max_depth=10, total=   1.0s\n",
      "[CV] n_estimators=300, min_samples_split=4, min_samples_leaf=3, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=300, min_samples_split=4, min_samples_leaf=3, max_features=sqrt, max_depth=10, total=   1.0s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, total=   0.8s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, total=   0.8s\n",
      "[CV] n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=None, total=   1.5s\n",
      "[CV] n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=None, total=   1.6s\n",
      "[CV] n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=None, total=   1.4s\n",
      "[CV] n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=None, total=   1.5s\n",
      "[CV] n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=None, total=   1.3s\n",
      "[CV] n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5, total=   1.3s\n",
      "[CV] n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5, total=   1.4s\n",
      "[CV] n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5, total=   1.4s\n",
      "[CV] n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5, total=   1.3s\n",
      "[CV] n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=400, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5, total=   1.4s\n",
      "[CV] n_estimators=50, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=50, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   0.3s\n",
      "[CV] n_estimators=50, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=50, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=50, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=50, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=50, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=50, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=50, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=50, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=5, min_samples_leaf=3, max_features=sqrt, max_depth=None \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, min_samples_split=5, min_samples_leaf=3, max_features=sqrt, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=100, min_samples_split=5, min_samples_leaf=3, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=5, min_samples_leaf=3, max_features=sqrt, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=100, min_samples_split=5, min_samples_leaf=3, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=5, min_samples_leaf=3, max_features=sqrt, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=100, min_samples_split=5, min_samples_leaf=3, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=5, min_samples_leaf=3, max_features=sqrt, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=100, min_samples_split=5, min_samples_leaf=3, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=5, min_samples_leaf=3, max_features=sqrt, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=100, min_samples_split=3, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=3, min_samples_leaf=1, max_features=auto, max_depth=30, total=   0.4s\n",
      "[CV] n_estimators=100, min_samples_split=3, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=3, min_samples_leaf=1, max_features=auto, max_depth=30, total=   0.4s\n",
      "[CV] n_estimators=100, min_samples_split=3, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=3, min_samples_leaf=1, max_features=auto, max_depth=30, total=   0.4s\n",
      "[CV] n_estimators=100, min_samples_split=3, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=3, min_samples_leaf=1, max_features=auto, max_depth=30, total=   0.4s\n",
      "[CV] n_estimators=100, min_samples_split=3, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=3, min_samples_leaf=1, max_features=auto, max_depth=30, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   41.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=1),\n",
       "                   param_distributions={'max_depth': [None, 5, 10, 20, 30],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4],\n",
       "                                        'min_samples_split': [2, 3, 4, 5],\n",
       "                                        'n_estimators': [50, 100, 200, 300,\n",
       "                                                         400]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Now we create the dictionary of the hyperparameters\n",
    "\n",
    "grid={'max_depth':[None,5,10,20,30],\n",
    "    'max_features':['auto','sqrt'],\n",
    "    'min_samples_leaf':[1,2,3,4],\n",
    "    'min_samples_split':[2,3,4,5],\n",
    "    'n_estimators':[50,100,200,300,400]\n",
    "    }\n",
    "\n",
    "np.random.seed(25)\n",
    "# Now we import the data\n",
    "\n",
    "x=hd_shuffled.drop('target',axis=1)\n",
    "y=hd_shuffled['target']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "# Instantiate the RandomForest Classifier\n",
    "\n",
    "clf=RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# Set up Random Search CV\n",
    "\n",
    "rs_clf=RandomizedSearchCV(estimator=clf,\n",
    "                      param_distributions=grid,\n",
    "                      n_iter=10,\n",
    "                      cv=5,\n",
    "                      verbose=2)\n",
    "rs_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "incredible-finland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we extract the best possible parametrs from the above outputs\n",
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "boxed-direction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score    :88.52459016393442%\n",
      "Precision Score   :88.09523809523809%\n",
      "Recall Score      :94.87179487179486%\n",
      "F1 Score          :91.35802469135803%\n"
     ]
    }
   ],
   "source": [
    "# we make the predictions with the best Hyper parameters\n",
    "rs_y_preds=rs_clf.predict(x_test)\n",
    "\n",
    "# Now we make the prediction\n",
    "rs_metrics=evae_score(y_test,rs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-forum",
   "metadata": {},
   "source": [
    "# Hyperparameters with GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "established-relative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': [None, 5, 10, 20, 30],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'min_samples_leaf': [1, 2, 3, 4],\n",
       " 'min_samples_split': [2, 3, 4, 5],\n",
       " 'n_estimators': [50, 100, 200, 300, 400]}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-configuration",
   "metadata": {},
   "source": [
    "    Here in grid search cv it will check all the possibilities unlike random search which checks only limited.\n",
    "    So we can make the sizes a tad bit smaller for the fast output. Although we can select evrything if the hard disk supports for larger data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-acrylic",
   "metadata": {},
   "source": [
    "# Now finally putting it all together!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-clinton",
   "metadata": {},
   "source": [
    "Here we are going to learn about sklearn pipeline, please use below url\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "ambient-offset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors    Price\n",
       "0   Honda  White        35431.0    4.0  15323.0\n",
       "1     BMW   Blue       192714.0    5.0  19943.0\n",
       "2   Honda  White        84714.0    4.0  28343.0\n",
       "3  Toyota  White       154365.0    4.0  13434.0\n",
       "4  Nissan   Blue       181577.0    3.0  14043.0"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data\n",
    "data= pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "noted-database",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              object\n",
       "Colour            object\n",
       "Odometer (KM)    float64\n",
       "Doors            float64\n",
       "Price            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data types of each column\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "figured-seeker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now check for the NAN values or Missing values \n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-crazy",
   "metadata": {},
   "source": [
    "# Things to Remember\n",
    "\n",
    "* All data should be Numerical\n",
    "* There should be no missing values\n",
    "* Manipulate the test set, same as the trained set\n",
    "* Never test the data which you have already trained on\n",
    "* Tune Hyper parameters on validation set (or) use cross validation\n",
    "* one best performance metric doesn't mean it is the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-copying",
   "metadata": {},
   "source": [
    "# Steps we want to do in below cell\n",
    "* Fill the missing values\n",
    "* Convert data into numbers( by one hot encoder or dummy values)\n",
    "* Model our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-kidney",
   "metadata": {},
   "source": [
    "**Pipeline**\n",
    "* It is basically arranging different process in a pipeline, and defining which steps to perform in order.\n",
    "* The Steps contain tuple values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "innocent-evanescence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3283522576968587"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the data ready\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Modelling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# RandomSeed\n",
    "np.random.seed(25)\n",
    "\n",
    "# import the data\n",
    "data=pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "data.dropna(subset=['Price'],inplace=True)\n",
    "\n",
    "# Define Different features and transform pipeline\n",
    "# Here we have to define all the different features like categorical & numerical and fill it with the dummy values\n",
    "categorical_features=['Make','Colour']\n",
    "categorical_transformer=Pipeline(steps=[('imputer',SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "                                       ('oneHot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "door_feature=['Doors']\n",
    "door_transformer=Pipeline(steps=[('imputer',SimpleImputer(strategy='constant',fill_value=4))])\n",
    "\n",
    "numeric_feature=['Odometer (KM)']\n",
    "numeric_transformer=Pipeline(steps=[('imputer',SimpleImputer(strategy='mean'))])\n",
    "\n",
    "# Setting up preprocessing steps (fill missing values and convert them to numbers)\n",
    "\n",
    "preprocessor= ColumnTransformer(transformers=[('cat',categorical_transformer,categorical_features),\n",
    "                                              ('door',door_transformer,door_feature),\n",
    "                                              ('odometer',numeric_transformer,numeric_feature)])\n",
    "\n",
    "\n",
    "# Creating a pipeline and modelling steps\n",
    "model=Pipeline(steps=[('preprocessor',preprocessor),\n",
    "                     ('model',RandomForestRegressor())])\n",
    "\n",
    "# Split data\n",
    "x=data.drop('Price',axis=1)\n",
    "y=data['Price']\n",
    "\n",
    "# train test split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "baseline_metrics=model.score(x_test,y_test)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "thousand-grove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.7s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.6s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.6s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.8s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.6s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.7s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.7s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.6s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.7s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.6s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   1.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   1.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   1.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   1.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   1.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   1.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   1.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   1.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   1.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   1.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=1, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.4s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.4s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.5s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.5s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=mean, total=   0.4s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.4s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.4s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.4s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.4s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__odometer__imputer__strategy=median, total=   0.4s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.7s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.9s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=mean, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=200, preprocessor__odometer__imputer__strategy=median, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   38.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('cat',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(fill_value='missing',\n",
       "                                                                                                        strategy='constant')),\n",
       "                                                                                         ('oneHot',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['Make',\n",
       "                                                                          'Colour']),\n",
       "                                                                        ('door',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(fill_value=4,\n",
       "                                                                                                        strategy='constant'))]),\n",
       "                                                                         ['Doors']),\n",
       "                                                                        ('odometer',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         ['Odometer '\n",
       "                                                                          '(KM)'])])),\n",
       "                                       ('model', RandomForestRegressor())]),\n",
       "             param_grid={'model__max_depth': [None, 5],\n",
       "                         'model__max_features': ['auto'],\n",
       "                         'model__min_samples_split': [1, 2],\n",
       "                         'model__n_estimators': [100, 200],\n",
       "                         'preprocessor__odometer__imputer__strategy': ['mean',\n",
       "                                                                       'median']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we improvise the above model using hyperparameter fine tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe_grid={\n",
    "    'preprocessor__odometer__imputer__strategy':['mean','median'],\n",
    "    'model__n_estimators':[100,200],\n",
    "    'model__min_samples_split':[1,2],\n",
    "    'model__max_depth':[None,5],\n",
    "    'model__max_features':['auto']\n",
    "}\n",
    "\n",
    "gs_model=GridSearchCV(model,pipe_grid,cv=5,verbose=2)\n",
    "gs_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "generic-ordering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 5,\n",
       " 'model__max_features': 'auto',\n",
       " 'model__min_samples_split': 2,\n",
       " 'model__n_estimators': 200,\n",
       " 'preprocessor__odometer__imputer__strategy': 'median'}"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.best_params_\n",
    "# Checking the best parameters abtained from above fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "suffering-affiliate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3875247407177823"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.score(x_test,y_test)\n",
    "# As we can see the model has performed a tad bit better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-junior",
   "metadata": {},
   "source": [
    "# Now that we finally have wings\n",
    "\n",
    "# Let's Play!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "successful-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use all the other models to try and check in between the outputs\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression                     # Logistic Regression( It is a classifier)\n",
    "from sklearn.svm import SVC                                             # Support Vector Machine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier                      # K -Nearest Neighbors\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier          # Gaussian Process Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier                         # Decision Tree Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier,   # Random Forest and AdaBoost Classifiers\n",
    "from sklearn.naive_bayes import GaussianNB                              # Gaussian Naive bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "departmental-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "collaborative-plasma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "x=hd.drop('target',axis=1)\n",
    "y=hd['target']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(x_train,y_train)\n",
    "y_preds=clf.predict(x_test)\n",
    "\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "private-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\shanm\\Desktop\\MiniConda\\sampleproject\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.491803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.672131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.639344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.836066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.918033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcess Classifier</th>\n",
       "      <td>0.803279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.639344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>0.672131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive bayes</th>\n",
       "      <td>0.836066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0\n",
       "LinearSVC                   0.491803\n",
       "KNN                         0.672131\n",
       "SVC                         0.639344\n",
       "LogisticRegression          0.836066\n",
       "RandomForestClassifier      0.918033\n",
       "GaussianProcess Classifier  0.803279\n",
       "Decision Tree               0.639344\n",
       "Ada Boost                   0.672131\n",
       "Gaussian Naive bayes        0.836066"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "          'LinearSVC': LinearSVC(),\n",
    "          'KNN': KNeighborsClassifier(),\n",
    "          'SVC': SVC(),\n",
    "          'LogisticRegression': LogisticRegression(),\n",
    "          'RandomForestClassifier': RandomForestClassifier(),\n",
    "          'GaussianProcess Classifier':GaussianProcessClassifier(),\n",
    "          'Decision Tree':DecisionTreeClassifier(),\n",
    "          'Ada Boost': AdaBoostClassifier(),\n",
    "          'Gaussian Naive bayes':GaussianNB()\n",
    "         }\n",
    "np.random.seed(25)\n",
    "# Create an empty dictionary called results\n",
    "results = {}\n",
    "A=list(models.values())\n",
    "B=[]\n",
    "for i in A:\n",
    "    clf=A[0]\n",
    "    clf.fit(x_train,y_train)\n",
    "    B.append(clf.score(x_test,y_test))\n",
    "B\n",
    "D=pd.DataFrame(B,list(models.keys()))\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "about-irish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets Plot the output for better view\n",
    "\n",
    "D.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now perform hyper parameter fine tuning for improving the model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
